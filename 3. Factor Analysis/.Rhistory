# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
# You may need to install these packages if you haven't already.
#install.packages("ggplot2")
#install.packages("ggforce")
library(ggplot2)
library(ggforce)
# Chunk 3
# Combine all points into a single data frame with a 'type' column.
points_df <- data.frame(
x = c(2, 3, 2.5, 3.5, 5),
y = c(2, 2, 2.8, 2.2, 5),
type = factor(c("Core", "Core", "Core", "Border", "Noise"),
levels = c("Core", "Border", "Noise"))
)
# Define epsilon and create a data frame for the core point circles
epsilon <- 1.0
core_points_circles <- data.frame(
x0 = c(2, 3, 2.5),
y0 = c(2, 2, 2.8),
r = epsilon
)
# Chunk 4
ggplot() +
# Draw the epsilon circles for core points
geom_circle(
data = core_points_circles,
aes(x0 = x0, y0 = y0, r = r),
color = "gray",
fill = "gray",
alpha = 0.2,
linetype = "dashed"
) +
# Draw the data points
geom_point(
data = points_df,
aes(x = x, y = y, shape = type, color = type),
size = 5,
stroke = 1.5 # Makes shapes like 'x' thicker
) +
# Set custom colors and shapes to match the Python plot
scale_color_manual(values = c(Core = "black", Border = "gray", Noise = "black")) +
scale_shape_manual(values = c(Core = 16, Border = 16, Noise = 4)) + # 16 is a solid circle, 4 is an 'x'
# Set axis limits and ensure aspect ratio is equal so circles are not distorted
coord_fixed(xlim = c(0, 6), ylim = c(0, 6)) +
# Add titles and labels
labs(
title = "DBSCAN Geometric Intuition",
x = NULL, y = NULL, color = "Point Type", shape = "Point Type"
) +
# Apply a clean theme and add a grid
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "top"
)
#DBSCAN for Sample data-2
#Step 1: Install and Load Required Packages ---
# You may need to install these packages if you haven't already.
install.packages("mlbench")
library(mlbench)
library(dbscan)
library(ggplot2)
library(mlbench)
library(dbscan)
library(ggplot2)
#Step 2: Generate Synthetic Data ---
# The mlbench.spirals() function can create a similar non-linear dataset.
# We'll use two spirals, which serve a similar purpose to the 'moons' dataset.
# `set.seed()` is the R equivalent of Python's `random_state`.
set.seed(42)
moons_data <- mlbench.spirals(n = 300, cycles = 1, sd = 0.1)
X <- moons_data$x
#Step 3: Standardize the Data ---
# The scale() function in R standardizes the data (mean=0, sd=1),
# similar to StandardScaler in scikit-learn.
X_scaled <- scale(X)
#Step 4: Apply DBSCAN Algorithm ---
# Use the dbscan() function.
# - eps = 0.3: Defines the radius of the neighborhood.
# - minPts = 5: The minimum number of points required for a core point.
dbscan_result <- dbscan(X_scaled, eps = 0.3, minPts = 5)
#Step 5: Plot the Results ---
# We use ggplot2 for a high-quality visualization.
# First, create a data frame for plotting.
plot_data <- data.frame(
Feature1 = X_scaled[, 1],
Feature2 = X_scaled[, 2],
Cluster = as.factor(dbscan_result$cluster) # Convert cluster numbers to a factor for coloring
)
# Create the plot
ggplot(plot_data, aes(x = Feature1, y = Feature2, color = Cluster)) +
geom_point(size = 3) +
labs(
title = "DBSCAN Clustering",
x = "Feature 1",
y = "Feature 2",
color = "Cluster"
) +
theme_bw() + # A clean black and white theme
theme(plot.title = element_text(hjust = 0.5)) # Center the plot title
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
# You may need to install these packages if you haven't already.
#install.packages("ggplot2")
#install.packages("ggforce")
library(ggplot2)
library(ggforce)
# Chunk 3
# Combine all points into a single data frame with a 'type' column.
points_df <- data.frame(
x = c(2, 3, 2.5, 3.5, 5),
y = c(2, 2, 2.8, 2.2, 5),
type = factor(c("Core", "Core", "Core", "Border", "Noise"),
levels = c("Core", "Border", "Noise"))
)
# Define epsilon and create a data frame for the core point circles
epsilon <- 1.0
core_points_circles <- data.frame(
x0 = c(2, 3, 2.5),
y0 = c(2, 2, 2.8),
r = epsilon
)
# Chunk 4
ggplot() +
# Draw the epsilon circles for core points
geom_circle(
data = core_points_circles,
aes(x0 = x0, y0 = y0, r = r),
color = "gray",
fill = "gray",
alpha = 0.2,
linetype = "dashed"
) +
# Draw the data points
geom_point(
data = points_df,
aes(x = x, y = y, shape = type, color = type),
size = 5,
stroke = 1.5 # Makes shapes like 'x' thicker
) +
# Set custom colors and shapes to match the Python plot
scale_color_manual(values = c(Core = "black", Border = "gray", Noise = "black")) +
scale_shape_manual(values = c(Core = 16, Border = 16, Noise = 4)) + # 16 is a solid circle, 4 is an 'x'
# Set axis limits and ensure aspect ratio is equal so circles are not distorted
coord_fixed(xlim = c(0, 6), ylim = c(0, 6)) +
# Add titles and labels
labs(
title = "DBSCAN Geometric Intuition",
x = NULL, y = NULL, color = "Point Type", shape = "Point Type"
) +
# Apply a clean theme and add a grid
theme_bw() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "top"
)
# Chunk 5
# You may need to install these packages if you haven't already.
#install.packages("mlbench")
#install.packages("dbscan")
#install.packages("ggplot2")
library(mlbench)
library(dbscan)
library(ggplot2)
# Chunk 6
# The mlbench.spirals() function can create a similar non-linear dataset.
# We'll use two spirals, which serve a similar purpose to the 'moons' dataset.
# `set.seed()` is the R equivalent of Python's `random_state`.
set.seed(42)
moons_data <- mlbench.spirals(n = 300, cycles = 1, sd = 0.1)
X <- moons_data$x
# Chunk 7
# The scale() function in R standardizes the data (mean=0, sd=1),
# similar to StandardScaler in scikit-learn.
X_scaled <- scale(X)
# Chunk 8
# Use the dbscan() function.
# - eps = 0.3: Defines the radius of the neighborhood.
# - minPts = 5: The minimum number of points required for a core point.
dbscan_result <- dbscan(X_scaled, eps = 0.3, minPts = 5)
# Chunk 9
# We use ggplot2 for a high-quality visualization.
# First, create a data frame for plotting.
plot_data <- data.frame(
Feature1 = X_scaled[, 1],
Feature2 = X_scaled[, 2],
Cluster = as.factor(dbscan_result$cluster) # Convert cluster numbers to a factor for coloring
)
# Create the plot
ggplot(plot_data, aes(x = Feature1, y = Feature2, color = Cluster)) +
geom_point(size = 3) +
labs(
title = "DBSCAN Clustering",
x = "Feature 1",
y = "Feature 2",
color = "Cluster"
) +
theme_bw() + # A clean black and white theme
theme(plot.title = element_text(hjust = 0.5)) # Center the plot title
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
#Step 2: Populate the matrix with distance data ---
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
#Step 3: Convert the matrix to a distance object ---
# The cmdscale function works with distance objects.
# We also reflect the lower triangle to the upper triangle to make it a full symmetric matrix.
dist_data <- as.dist(Air_line_data_2)
#Step 4: Perform Classical (Metric) MDS ---
# cmdscale() performs the scaling, reducing the data to k=2 dimensions.
MMDS_1 <- cmdscale(dist_data, k = 2)
#Step 5: Plot the results ---
# 'type="n"' creates an empty plot.
plot(MMDS_1[, 1], MMDS_1[, 2], type = "n", xlab = "", ylab = "", axes = FALSE, main = "cmdscale (stats)")
# 'text()' adds the city names to the plot at their new 2D coordinates.
text(MMDS_1[, 1], MMDS_1[, 2], labels = rownames(MMDS_1), cex = 0.9, xpd = TRUE)
#Step 1: Load the MASS library for the isoMDS function ---
library(MASS)
#Step 2: Create an empty matrix for the dissimilarity data ---
World_war_Politicians_data_1 <- matrix(ncol = 12, nrow = 12)
# Assign names to the columns and rows
politician_names <- c("Hitler", "Mussolini", "Churchill", "Eisenhower", "Stalin", "Attlee", "Franco", "De_Gaulle", "Mao_Tse", "Truman", "Chamberlain", "Tito")
colnames(World_war_Politicians_data_1) <- politician_names
rownames(World_war_Politicians_data_1) <- politician_names
#Step 3: Populate the matrix with dissimilarity data ---
# Fill the lower triangle of the matrix with the provided dissimilarity scores.
World_war_Politicians_data_1[lower.tri(World_war_Politicians_data_1)] <- c(5, 11, 15, 8, 17, 5, 10, 16, 17, 12, 16, 14, 16, 13, 18, 3, 11, 18, 18, 14, 17, 7, 11, 11, 12, 5, 16, 8, 10, 8, 16, 16, 14, 8, 17, 6, 7, 12, 15, 13, 11, 12, 14, 16, 12, 16, 12, 16, 12, 9, 13, 9, 17, 16, 10, 12, 13, 9, 11, 7, 12, 17, 10, 9, 11, 15)
# Set the diagonal to zero
diag(World_war_Politicians_data_1) <- 0
#Step 4: Convert the matrix to a distance object ---
dist_politicians <- as.dist(World_war_Politicians_data_1)
#Step 5: Perform Non-Metric MDS ---
# The isoMDS() function is used for non-metric scaling.
NMMDS_1 <- isoMDS(dist_politicians, k = 2)
#Step 6: Plot the results ---
# Create an empty plot to place the labels on.
plot(NMMDS_1$points, type = "n", xlab = "", ylab = "", axes = FALSE)
# Add the politician names at their scaled coordinates.
text(NMMDS_1$points, labels = politician_names, cex = 0.9, xpd = TRUE)
#================================================
#Multidimensional scaling (MDS) using R
----------------Part(a)------------------
#================================================
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
#================================================
#Multidimensional scaling (MDS) using R
#---------Part(a)-----------#
#================================================
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
#Step 2: Populate the matrix with distance data ---
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
#Step 3: Convert the matrix to a distance object ---
# The cmdscale function works with distance objects.
# We also reflect the lower triangle to the upper triangle to make it a full symmetric matrix.
dist_data <- as.dist(Air_line_data_2)
#Step 4: Perform Classical (Metric) MDS ---
# cmdscale() performs the scaling, reducing the data to k=2 dimensions.
MMDS_1 <- cmdscale(dist_data, k = 2)
#Step 5: Plot the results ---
# 'type="n"' creates an empty plot.
plot(MMDS_1[, 1], MMDS_1[, 2], type = "n", xlab = "", ylab = "", axes = FALSE, main = "cmdscale (stats)")
# 'text()' adds the city names to the plot at their new 2D coordinates.
text(MMDS_1[, 1], MMDS_1[, 2], labels = rownames(MMDS_1), cex = 0.9, xpd = TRUE)
#================================================
#Multidimensional scaling (MDS) using R
#---------Part(b)-----------#
#================================================
#Step 1: Load the MASS library for the isoMDS function ---
library(MASS)
#Step 2: Create an empty matrix for the dissimilarity data ---
World_war_Politicians_data_1 <- matrix(ncol = 12, nrow = 12)
# Assign names to the columns and rows
politician_names <- c("Hitler", "Mussolini", "Churchill", "Eisenhower", "Stalin", "Attlee", "Franco", "De_Gaulle", "Mao_Tse", "Truman", "Chamberlain", "Tito")
colnames(World_war_Politicians_data_1) <- politician_names
rownames(World_war_Politicians_data_1) <- politician_names
#Step 3: Populate the matrix with dissimilarity data ---
# Fill the lower triangle of the matrix with the provided dissimilarity scores.
World_war_Politicians_data_1[lower.tri(World_war_Politicians_data_1)] <- c(5, 11, 15, 8, 17, 5, 10, 16, 17, 12, 16, 14, 16, 13, 18, 3, 11, 18, 18, 14, 17, 7, 11, 11, 12, 5, 16, 8, 10, 8, 16, 16, 14, 8, 17, 6, 7, 12, 15, 13, 11, 12, 14, 16, 12, 16, 12, 16, 12, 9, 13, 9, 17, 16, 10, 12, 13, 9, 11, 7, 12, 17, 10, 9, 11, 15)
# Set the diagonal to zero
diag(World_war_Politicians_data_1) <- 0
#Step 4: Convert the matrix to a distance object ---
dist_politicians <- as.dist(World_war_Politicians_data_1)
#Step 5: Perform Non-Metric MDS ---
# The isoMDS() function is used for non-metric scaling.
NMMDS_1 <- isoMDS(dist_politicians, k = 2)
#Step 6: Plot the results ---
# Create an empty plot to place the labels on.
plot(NMMDS_1$points, type = "n", xlab = "", ylab = "", axes = FALSE)
# Add the politician names at their scaled coordinates.
text(NMMDS_1$points, labels = politician_names, cex = 0.9, xpd = TRUE)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
# Chunk 3
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
# Chunk 4
# The cmdscale function works with distance objects.
# We also reflect the lower triangle to the upper triangle to make it a full symmetric matrix.
dist_data <- as.dist(Air_line_data_2)
# Chunk 5
# cmdscale() performs the scaling, reducing the data to k=2 dimensions.
MMDS_1 <- cmdscale(dist_data, k = 2)
# Chunk 6
# 'type="n"' creates an empty plot.
plot(MMDS_1[, 1], MMDS_1[, 2], type = "n", xlab = "", ylab = "", axes = FALSE, main = "cmdscale (stats)")
# 'text()' adds the city names to the plot at their new 2D coordinates.
text(MMDS_1[, 1], MMDS_1[, 2], labels = rownames(MMDS_1), cex = 0.9, xpd = TRUE)
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
had(Air_line_data_2)
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
head(Air_line_data_2)
#Step 1: Create an empty matrix and define its dimensions ---
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
head(Air_line_data_2)
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
Air_line_data_2
# cmdscale() performs the scaling, reducing the data to k=2 dimensions.
MMDS_1 <- cmdscale(dist_data, k = 2)
MMDS_1
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
# The matrix will hold the distance data between 10 U.S. cities.
Air_line_data_2 <- matrix(ncol = 10, nrow = 10)
# Assign city names to the columns and rows
colnames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
rownames(Air_line_data_2) <- c("Atlanta", "Chicago", "Denver", "Houston", "Los_Angeles", "Miami", "New_York", "San_Francisco", "Seattle", "Washington_D.C")
# Chunk 3
# The distances are fed into the lower triangle of the matrix.
Air_line_data_2[lower.tri(Air_line_data_2)] <- c(587, 1212, 701, 1936, 604, 748, 2139, 2182, 543, 920, 940, 1745, 1188, 713, 1858, 1737, 597, 879, 831, 1726, 1631, 949, 1021, 1494, 1374, 968, 1420, 1645, 1891, 1220, 2339, 2451, 347, 959, 2300, 1092, 2594, 2734, 923, 2571, 2408, 205, 678, 2442, 2329)
# Set the diagonal to zero (distance from a city to itself is 0)
diag(Air_line_data_2) <- 0
# Chunk 4
# The cmdscale function works with distance objects.
# We also reflect the lower triangle to the upper triangle to make it a full symmetric matrix.
dist_data <- as.dist(Air_line_data_2)
# Chunk 5
# cmdscale() performs the scaling, reducing the data to k=2 dimensions.
MMDS_1 <- cmdscale(dist_data, k = 2)
# Chunk 6
# 'type="n"' creates an empty plot.
plot(MMDS_1[, 1], MMDS_1[, 2], type = "n", xlab = "", ylab = "", axes = FALSE, main = "cmdscale (stats)")
# 'text()' adds the city names to the plot at their new 2D coordinates.
text(MMDS_1[, 1], MMDS_1[, 2], labels = rownames(MMDS_1), cex = 0.9, xpd = TRUE)
# Chunk 7
library(MASS)
# Chunk 8
World_war_Politicians_data_1 <- matrix(ncol = 12, nrow = 12)
# Assign names to the columns and rows
politician_names <- c("Hitler", "Mussolini", "Churchill", "Eisenhower", "Stalin", "Attlee", "Franco", "De_Gaulle", "Mao_Tse", "Truman", "Chamberlain", "Tito")
colnames(World_war_Politicians_data_1) <- politician_names
rownames(World_war_Politicians_data_1) <- politician_names
# Chunk 9
# Fill the lower triangle of the matrix with the provided dissimilarity scores.
World_war_Politicians_data_1[lower.tri(World_war_Politicians_data_1)] <- c(5, 11, 15, 8, 17, 5, 10, 16, 17, 12, 16, 14, 16, 13, 18, 3, 11, 18, 18, 14, 17, 7, 11, 11, 12, 5, 16, 8, 10, 8, 16, 16, 14, 8, 17, 6, 7, 12, 15, 13, 11, 12, 14, 16, 12, 16, 12, 16, 12, 9, 13, 9, 17, 16, 10, 12, 13, 9, 11, 7, 12, 17, 10, 9, 11, 15)
# Set the diagonal to zero
diag(World_war_Politicians_data_1) <- 0
# Chunk 10
dist_politicians <- as.dist(World_war_Politicians_data_1)
# Chunk 11
# The isoMDS() function is used for non-metric scaling.
NMMDS_1 <- isoMDS(dist_politicians, k = 2)
# Chunk 12
# Create an empty plot to place the labels on.
plot(NMMDS_1$points, type = "n", xlab = "", ylab = "", axes = FALSE)
# Add the politician names at their scaled coordinates.
text(NMMDS_1$points, labels = politician_names, cex = 0.9, xpd = TRUE)
# In this example, we will perform Correspondence Analysis on the "USArrests" data set, which contains statistics on
# arrests made in each of the 50 US states in 1973. This data set is quantitative, making it suitable for Correspondence
# Analysis.
# --- Using FactoMineR package ---
install.packages("FactoMineR")
library(FactoMineR)
data("USArrests")
result = CA(USArrests)
# --- Visualize the Results ---
# To visualize the results, we will use the "factoextra" package to create a biplot with the results of the Correspondence Analysis.
# To install the "factoextra" package, use the following code:
install.packages("factoextra")
library(factoextra)
fviz_ca_biplot(result, repel = TRUE)
# --- Using ca package ---
# We'll again use the "USArrests" data set, which contains statistics on arrests made in each of the 50 US states in 1973
# perform correspondence analysis
install.packages("ca")
library(ca)
res.ca <- ca(USArrests, graph = FALSE)
# --- Extract Eigenvalues and Create a Scree Plot ---
# extract eigenvalues
eig <- get_eigenvalue(res.ca)
eig
# visualize eigenvalues
fviz_eig(res.ca)
# --- Row and column profiles ---
row.profiles <- get_ca_row(res.ca)
row.profiles
col.profiles <- get_ca_col(res.ca)
col.profiles
# --- Visualization of Row and Column Profiles ---
fviz_ca_row(res.ca)
fviz_ca_col(res.ca)
# --- Create a Biplot ---
# We can also create a biplot to visualize the relationship between the rows and columns of the analysis.
# And from the previous example, we know that fviz_ca_biplot() function creates a scatter plot of the rows and columns of the analysis
# with arrows indicating the strength and direction of the relationship between them.
fviz_ca_biplot(res.ca)
library(FactoMineR)   # For CA function
library(factoextra)   # For visualization
library(ca)           # For correspondence analysis
library(FactoMineR)   # For CA function
library(factoextra)   # For visualization
library(ca)           # For correspondence analysis
data("USArrests")  # Built-in dataset
head(USArrests)    # Preview first few rows
#Step  2. Correspondence Analysis using FactoMineR
ca_result_facto <- CA(USArrests)  # Perform CA
# Visualization: Biplot
fviz_ca_biplot(ca_result_facto, repel = TRUE)
#Step  3. Correspondence Analysis using 'ca' package
ca_result <- ca(USArrests, graph = FALSE)  # Perform CA
#Step  4. Eigenvalues & Scree Plot
eig_values <- get_eigenvalue(ca_result)
print(eig_values)         # Display eigenvalues
fviz_eig(ca_result)       # Scree plot
#Step  5. Row & Column Profiles
row_profiles <- get_ca_row(ca_result)
print(row_profiles)
col_profiles <- get_ca_col(ca_result)
print(col_profiles)
#Step  7. Biplot (Rows & Columns)
fviz_ca_biplot(ca_result, repel = TRUE)
fviz_ca_col(ca_result)    # Column profiles
#Step  6. Visualize Row & Column Profiles
fviz_ca_row(ca_result)    # Row profiles
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
#install.packages(c("FactoMineR", "factoextra", "ca"))
library(FactoMineR)   # For CA function
library(factoextra)   # For visualization
library(ca)           # For correspondence analysis
data("USArrests")  # Built-in dataset
head(USArrests)    # Preview first few rows
# Chunk 3
ca_result_facto <- CA(USArrests)  # Perform CA
# Visualization: Biplot
fviz_ca_biplot(ca_result_facto, repel = TRUE)
# Chunk 4
ca_result <- ca(USArrests, graph = FALSE)  # Perform CA
# Chunk 5
eig_values <- get_eigenvalue(ca_result)
print(eig_values)         # Display eigenvalues
fviz_eig(ca_result)       # Scree plot
# Chunk 6
row_profiles <- get_ca_row(ca_result)
print(row_profiles)
col_profiles <- get_ca_col(ca_result)
print(col_profiles)
# Chunk 7
fviz_ca_row(ca_result)    # Row profiles
fviz_ca_col(ca_result)    # Column profiles
# Chunk 8
fviz_ca_biplot(ca_result, repel = TRUE)
